{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "cell_execution_strategy": "setup",
      "authorship_tag": "ABX9TyONNnpIO+Ov1qvyCGssUstl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eyaler/constrained/blob/main/compact/ted_multilingual_counter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyICU\n",
        "\n",
        "import icu\n",
        "from collections import Counter\n",
        "from math import exp, log\n",
        "import re\n",
        "\n",
        "\n",
        "def clean(s):\n",
        "  return re.sub('[\\u200b-\\u200f♪♫]', '', s).strip()\n",
        "\n",
        "\n",
        "trans = str.maketrans('ς' + 'ךםןףץ' + '٩٨٧٦٥٤٣٢١٠' + '،' + '\\xa0', 'σ' + 'כמנפצ' + '9876543210' + ',' + ' ')\n",
        "print([(chr(k), chr(v)) for k, v in trans.items()])\n",
        "\n",
        "\n",
        "def norm(s):\n",
        "  return s.translate(trans).lower()\n",
        "\n",
        "\n",
        "def perplexity(cnt):\n",
        "  s = sum(cnt.values())\n",
        "  return exp(-sum(log(c / s) * c for c in cnt.values()) / s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EiCxwS6_S2W2",
        "outputId": "76938005-771d-4ba4-a82c-63cd3323e97d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyICU in /usr/local/lib/python3.12/dist-packages (2.16)\n",
            "[('ς', 'σ'), ('ך', 'כ'), ('ם', 'מ'), ('ן', 'נ'), ('ף', 'פ'), ('ץ', 'צ'), ('٩', '9'), ('٨', '8'), ('٧', '7'), ('٦', '6'), ('٥', '5'), ('٤', '4'), ('٣', '3'), ('٢', '2'), ('١', '1'), ('٠', '0'), ('،', ','), ('\\xa0', ' ')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TED2020\n",
        "\n",
        "    @inproceedings{reimers-2020-multilingual-sentence-bert,\n",
        "      title = \"Making Monolingual Sentence Embeddings Multilingual using Knowledge Distillation\",\n",
        "      author = \"Reimers, Nils and Gurevych, Iryna\",\n",
        "      booktitle = \"Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing\",\n",
        "      month = \"11\",\n",
        "      year = \"2020\",\n",
        "      publisher = \"Association for Computational Linguistics\",\n",
        "      url = \"https://arxiv.org/abs/2004.09813\",\n",
        "    }\n",
        "\n",
        "https://arxiv.org/abs/2004.09813\n",
        "\n",
        "https://public.ukp.informatik.tu-darmstadt.de/reimers/sentence-transformers/datasets/parallel-sentences-source-files.zip\n",
        "\n",
        "https://public.ukp.informatik.tu-darmstadt.de/reimers/sentence-transformers/datasets/parallel-sentences.tsv.gz"
      ],
      "metadata": {
        "id": "89FfTRBh0Hzi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://public.ukp.informatik.tu-darmstadt.de/reimers/sentence-transformers/datasets/parallel-sentences.tsv.gz -O parallel-sentences.tsv.gz\n",
        "!gunzip -f parallel-sentences.tsv.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O05p6l0hqBFI",
        "outputId": "8b7b9e1c-edb1-4d29-94ab-fbf2239f039b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-15 10:31:16--  https://public.ukp.informatik.tu-darmstadt.de/reimers/sentence-transformers/datasets/parallel-sentences.tsv.gz\n",
            "Resolving public.ukp.informatik.tu-darmstadt.de (public.ukp.informatik.tu-darmstadt.de)... 130.83.167.186\n",
            "Connecting to public.ukp.informatik.tu-darmstadt.de (public.ukp.informatik.tu-darmstadt.de)|130.83.167.186|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 581354214 (554M) [application/octet-stream]\n",
            "Saving to: ‘parallel-sentences.tsv.gz’\n",
            "\n",
            "parallel-sentences. 100%[===================>] 554.42M  7.54MB/s    in 1m 43s  \n",
            "\n",
            "2025-12-15 10:33:00 (5.37 MB/s) - ‘parallel-sentences.tsv.gz’ saved [581354214/581354214]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "\n",
        "bi = {}\n",
        "\n",
        "with open('parallel-sentences.tsv', newline='', encoding='utf-8') as f:\n",
        "    reader = csv.DictReader(f, delimiter='\\t', quoting=csv.QUOTE_NONE)\n",
        "    for row in reader:\n",
        "      clean_he = clean(row['he'])\n",
        "      if clean_he:\n",
        "        for lang in reader.fieldnames[1:]:\n",
        "          clean_lang = clean(row[lang])\n",
        "          if clean_lang:\n",
        "            if lang not in bi:\n",
        "              bi[lang] = [0, 0, Counter(), Counter(), 0]\n",
        "            bi[lang][0] += len(clean_lang)\n",
        "            bi[lang][1] += len(clean_he)\n",
        "            bi[lang][2].update(norm(clean_lang))\n",
        "            bi[lang][3].update(norm(clean_he))\n",
        "            bi[lang][4] += 1\n",
        "\n",
        "ted_2020 = dict(sorted([(k, (icu.Locale(k).getDisplayName(), v[0] / v[1], len(v[2]), perplexity(v[2]), perplexity(v[3]), v[4])) for k, v in bi.items()], key=lambda x: (x[1][1], x[0])))\n",
        "\n",
        "for code, (lang, rlen, symbols, perp, pheb, sents) in ted_2020.items():\n",
        "  print(f'({code}) {lang}\\t{round(rlen, 3):.3f} {symbols} {round(perp, 1):.1f} {round(perp / pheb * rlen, 3):.3f} ({sents})')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlgY8qPXuvD1",
        "outputId": "b36e8bc2-e5e9-4331-a60b-08d22109be5b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(zh) Chinese\t0.393 3855 499.3 9.953 (15672)\n",
            "(zh-tw) Chinese (Taiwan)\t0.431 6007 468.1 10.267 (343524)\n",
            "(zh-cn) Chinese (China)\t0.437 5293 449.3 9.990 (343160)\n",
            "(ja) Japanese\t0.556 3482 225.9 6.385 (329001)\n",
            "(ko) Korean\t0.690 2602 116.3 4.081 (341553)\n",
            "(am) Amharic\t0.786 279 63.3 2.497 (1023)\n",
            "(he) Hebrew\t1.000 174 19.7 1.000 (348918)\n",
            "(la) Latin\t1.003 30 18.1 0.954 (20)\n",
            "(tlh) Klingon\t1.082 42 21.9 1.266 (60)\n",
            "(ar) Arabic\t1.090 306 23.9 1.324 (343957)\n",
            "(arq) Algerian Arabic\t1.150 123 40.2 2.390 (1398)\n",
            "(ps) Pashto\t1.165 102 21.8 1.307 (962)\n",
            "(kk) Kazakh\t1.179 114 26.0 1.559 (9484)\n",
            "(szl) Silesian\t1.192 50 24.8 1.521 (102)\n",
            "(sl) Slovenian\t1.196 102 20.6 1.256 (42583)\n",
            "(th) Thai\t1.197 199 41.6 2.540 (153995)\n",
            "(pl) Polish\t1.198 181 25.4 1.545 (285764)\n",
            "(tt) Tatar\t1.201 72 26.0 1.578 (263)\n",
            "(cs) Czech\t1.206 157 27.0 1.661 (164327)\n",
            "(as) Assamese\t1.212 65 32.1 2.079 (41)\n",
            "(sk) Slovak\t1.220 127 26.2 1.624 (102958)\n",
            "(mr) Marathi\t1.220 159 30.6 1.906 (20287)\n",
            "(gu) Gujarati\t1.229 189 30.3 1.894 (10317)\n",
            "(sr) Serbian\t1.229 173 29.8 1.866 (235124)\n",
            "(bs) Bosnian\t1.233 78 20.6 1.296 (11058)\n",
            "(hr) Croatian\t1.237 158 20.7 1.305 (185771)\n",
            "(eo) Esperanto\t1.237 78 20.1 1.250 (11079)\n",
            "(ig) Igbo\t1.238 46 20.0 1.254 (207)\n",
            "(az) Azerbaijani\t1.241 76 24.8 1.556 (11402)\n",
            "(mn) Mongolian\t1.242 113 23.8 1.504 (23778)\n",
            "(uk) Ukrainian\t1.243 180 26.5 1.677 (188172)\n",
            "(tk) Turkmen\t1.245 56 24.9 1.605 (213)\n",
            "(ne) Nepali\t1.247 135 32.0 2.016 (4112)\n",
            "(fi) Finnish\t1.249 101 18.9 1.195 (43693)\n",
            "(be) Belarusian\t1.249 108 26.4 1.683 (10036)\n",
            "(lv) Latvian\t1.254 108 23.9 1.518 (53127)\n",
            "(srp) Serbian\t1.259 66 20.3 1.303 (2072)\n",
            "(et) Estonian\t1.260 90 19.4 1.248 (22960)\n",
            "(lt) Lithuanian\t1.260 121 22.4 1.438 (72639)\n",
            "(hi) Hindi\t1.264 182 30.1 1.941 (38823)\n",
            "(ast) Asturian\t1.266 54 20.3 1.243 (114)\n",
            "(af) Afrikaans\t1.267 70 19.2 1.225 (2180)\n",
            "(ku) Kurdish\t1.271 153 22.1 1.429 (49328)\n",
            "(si) Sinhala\t1.272 108 28.1 1.872 (1032)\n",
            "(tr) Turkish\t1.272 171 23.4 1.514 (323289)\n",
            "(ltg) Latgalian\t1.274 55 24.2 1.531 (88)\n",
            "(gl) Galician\t1.280 100 19.2 1.242 (31771)\n",
            "(sh) Serbo-Croatian\t1.282 68 20.4 1.344 (2314)\n",
            "(pa) Punjabi\t1.283 109 30.3 2.014 (758)\n",
            "(hu) Hungarian\t1.284 177 25.0 1.638 (266047)\n",
            "(te) Telugu\t1.285 136 31.6 2.086 (4582)\n",
            "(sv) Swedish\t1.285 123 21.0 1.372 (113285)\n",
            "(km) Khmer\t1.286 127 42.9 2.821 (782)\n",
            "(ka) Georgian\t1.289 106 22.4 1.475 (27608)\n",
            "(ru) Russian\t1.292 205 24.9 1.634 (340455)\n",
            "(mk) Macedonian\t1.295 114 20.1 1.321 (41316)\n",
            "(mt) Maltese\t1.296 51 24.5 1.566 (167)\n",
            "(sw) Swahili\t1.296 63 18.0 1.201 (7611)\n",
            "(fa) Persian\t1.297 213 20.1 1.329 (260503)\n",
            "(nn) Norwegian Nynorsk\t1.300 62 19.5 1.275 (1358)\n",
            "(nb) Norwegian Bokmål\t1.301 105 19.1 1.258 (27338)\n",
            "(ro) Romanian\t1.303 180 20.4 1.353 (299353)\n",
            "(bn) Bangla\t1.305 146 29.7 1.956 (10263)\n",
            "(ur) Urdu\t1.308 150 22.3 1.485 (14044)\n",
            "(bg) Bulgarian\t1.316 168 21.2 1.416 (241630)\n",
            "(eu) Basque\t1.319 85 17.6 1.180 (9991)\n",
            "(da) Danish\t1.319 119 19.3 1.293 (69516)\n",
            "(ha) Hausa\t1.322 35 15.6 1.035 (26)\n",
            "(en) English\t1.323 166 19.8 1.328 (348918)\n",
            "(ca) Catalan\t1.328 129 20.3 1.370 (49342)\n",
            "(nl) Dutch\t1.329 165 18.6 1.259 (294456)\n",
            "(kn) Kannada\t1.335 141 32.4 2.150 (2255)\n",
            "(pt) Portuguese\t1.339 180 19.8 1.350 (281367)\n",
            "(lo) Lao\t1.345 97 40.1 2.720 (443)\n",
            "(pt-br) Portuguese (Brazil)\t1.347 192 19.8 1.354 (346910)\n",
            "(vi) Vietnamese\t1.347 221 30.8 2.107 (303240)\n",
            "(es) Spanish\t1.362 265 19.4 1.340 (346255)\n",
            "(is) Icelandic\t1.367 66 23.4 1.627 (2393)\n",
            "(it) Italian\t1.373 187 18.8 1.313 (329554)\n",
            "(uz) Uzbek\t1.383 101 21.5 1.505 (5916)\n",
            "(sq) Albanian\t1.384 100 20.4 1.431 (67705)\n",
            "(ht) Haitian Creole\t1.387 60 19.8 1.370 (360)\n",
            "(hy) Armenian\t1.387 169 25.7 1.814 (36255)\n",
            "(tg) Tajik\t1.393 84 19.9 1.414 (548)\n",
            "(tl) Tagalog\t1.401 55 16.1 1.136 (1175)\n",
            "(ceb) Cebuano\t1.405 42 16.2 1.171 (98)\n",
            "(ky) Kyrgyz\t1.413 86 26.2 1.823 (697)\n",
            "(id) Indonesian\t1.414 152 17.7 1.275 (153281)\n",
            "(el) Greek\t1.420 210 23.9 1.729 (248936)\n",
            "(ms) Malay\t1.424 80 17.7 1.283 (11247)\n",
            "(de) German\t1.431 189 19.7 1.431 (277322)\n",
            "(oc) Occitan\t1.451 53 21.8 1.596 (32)\n",
            "(bo) Tibetan\t1.454 125 23.9 1.772 (950)\n",
            "(fr) French\t1.463 210 20.2 1.503 (343711)\n",
            "(my) Burmese\t1.467 213 35.0 2.609 (54327)\n",
            "(ml) Malayalam\t1.470 135 30.6 2.282 (4845)\n",
            "(fr-ca) French (Canada)\t1.471 114 20.4 1.517 (33057)\n",
            "(so) Somali\t1.481 60 17.0 1.271 (1979)\n",
            "(ga) Irish\t1.500 48 18.6 1.446 (79)\n",
            "(fil) Filipino\t1.502 67 15.8 1.195 (3370)\n",
            "(inh) Ingush\t1.503 54 22.1 1.639 (220)\n",
            "(ta) Tamil\t1.514 121 25.4 1.950 (11068)\n",
            "(ug) Uyghur\t1.523 94 25.3 1.882 (953)\n",
            "(lb) Luxembourgish\t1.555 53 20.0 1.549 (88)\n",
            "(mg) Malagasy\t1.577 65 17.0 1.329 (364)\n",
            "(bi) Bislama\t1.588 40 16.8 1.348 (31)\n",
            "(dz) Dzongkha\t1.622 71 22.8 1.925 (150)\n",
            "(hup) Hupa\t2.900 18 13.9 4.035 (1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TED-Parallel-Corpus\n",
        "\n",
        "    @techreport{kulkarni:hal-04702210,\n",
        "      TITLE = {{TED-Parallel-Corpus}},\n",
        "      AUTHOR = {Kulkarni, Ajinkya},\n",
        "      URL = {https://hal.science/hal-04702210},\n",
        "      NUMBER = {none},\n",
        "      INSTITUTION = {{CDAC ; Idiap Research Institure}},\n",
        "      YEAR = {2015},\n",
        "      MONTH = Jan,\n",
        "      KEYWORDS = {Machine translation ; Neural machine translation NMT ; NLP ; Multilingual},\n",
        "      PDF = {https://hal.science/hal-04702210v1/file/ted_parallel_corpus.pdf},\n",
        "      HAL_ID = {hal-04702210},\n",
        "      HAL_VERSION = {v1},\n",
        "    }\n",
        "\n",
        "https://hal.science/hal-04702210\n",
        "\n",
        "https://github.com/ajinkyakulkarni14/How-I-Extracted-TED-talks-for-parallel-Corpus-\n",
        "\n",
        "https://github.com/ajinkyakulkarni14/TED-Multilingual-Parallel-Corpus/"
      ],
      "metadata": {
        "id": "irnwWNux0cYu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/ajinkyakulkarni14/TED-Multilingual-Parallel-Corpus/raw/refs/heads/master/Multilingual_Parallel_Corpus/Multi_lingual_Parallel_corpus_1.zip -O Multi_lingual_Parallel_corpus_1.zip\n",
        "!unzip -o Multi_lingual_Parallel_corpus_1.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIYJkr7XpmVx",
        "outputId": "98ba2de4-3f5a-459b-aa80-cd32d84dfae8"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-15 10:45:18--  https://github.com/ajinkyakulkarni14/TED-Multilingual-Parallel-Corpus/raw/refs/heads/master/Multilingual_Parallel_Corpus/Multi_lingual_Parallel_corpus_1.zip\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/ajinkyakulkarni14/TED-Multilingual-Parallel-Corpus/refs/heads/master/Multilingual_Parallel_Corpus/Multi_lingual_Parallel_corpus_1.zip [following]\n",
            "--2025-12-15 10:45:18--  https://raw.githubusercontent.com/ajinkyakulkarni14/TED-Multilingual-Parallel-Corpus/refs/heads/master/Multilingual_Parallel_Corpus/Multi_lingual_Parallel_corpus_1.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 78542347 (75M) [application/zip]\n",
            "Saving to: ‘Multi_lingual_Parallel_corpus_1.zip’\n",
            "\n",
            "Multi_lingual_Paral 100%[===================>]  74.90M   189MB/s    in 0.4s    \n",
            "\n",
            "2025-12-15 10:45:19 (189 MB/s) - ‘Multi_lingual_Parallel_corpus_1.zip’ saved [78542347/78542347]\n",
            "\n",
            "Archive:  Multi_lingual_Parallel_corpus_1.zip\n",
            "  inflating: Multilingual_Parllel_corpus.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "last = 0\n",
        "sents = 0\n",
        "seen = set()\n",
        "multi = {}\n",
        "counters = {}\n",
        "\n",
        "with open(r'Multilingual_Parllel_corpus.txt', encoding='utf8') as f:\n",
        "  for line in f.readlines():\n",
        "    line = clean(line)\n",
        "    if re.match(r'\\d+:[a-z]{2}(-[a-z]{2})?:', line):\n",
        "      num = int(line.split(':', 1)[0])\n",
        "      if num != last:\n",
        "        assert not seen or len(seen) == 9, (last, seen)\n",
        "        seen = set()\n",
        "        last = num\n",
        "        sents += 1\n",
        "      parts = line.split(':', 2)\n",
        "      lang = parts[1]\n",
        "      if lang in seen:\n",
        "        continue\n",
        "      seen.add(lang)\n",
        "      if lang not in multi:\n",
        "        multi[lang] = 0\n",
        "        counters[lang] = Counter()\n",
        "      text = parts[2]\n",
        "    else:\n",
        "      text = ' ' + line\n",
        "    multi[lang] += len(text)\n",
        "    counters[lang].update(norm(text))\n",
        "\n",
        "print(f'{sents=}')\n",
        "ted_para = dict(sorted([(k, (icu.Locale(k).getDisplayName(), v / multi['he'], len(counters[k]), perplexity(counters[k]))) for k, v in multi.items()], key=lambda x: (x[1][1], x[0])))\n",
        "pheb_para = perplexity(counters['he'])\n",
        "for code, (lang, rlen, symbols, perp) in ted_para.items():\n",
        "  print(f'({code}) {lang}\\t{round(rlen, 3):.3f} {symbols} {round(perp, 1):.1f} {round(perp / pheb_para * rlen, 3):.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3ilrapGZSB2",
        "outputId": "94d24ced-1617-4aee-e7ad-f5e4c9a06a49"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sents=349049\n",
            "(he) Hebrew\t1.000 121 20.1 1.000\n",
            "(ar) Arabic\t1.104 268 24.2 1.323\n",
            "(ru) Russian\t1.322 149 25.3 1.660\n",
            "(nl) Dutch\t1.347 125 19.0 1.269\n",
            "(es) Spanish\t1.372 171 19.8 1.347\n",
            "(pt-br) Portuguese (Brazil)\t1.377 129 20.1 1.375\n",
            "(it) Italian\t1.399 122 19.2 1.332\n",
            "(de) German\t1.475 136 19.9 1.458\n",
            "(fr) French\t1.512 150 20.5 1.542\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "\n",
        "exclude = ['la',  'hup']  # Latin has only 20 parallel sentences, and Hupa 1\n",
        "\n",
        "output = []\n",
        "for code, (lang, rlen, *rest) in sorted(ted_2020.items(), key=lambda x: x[0] != 'he'):\n",
        "  if code in exclude:\n",
        "    continue\n",
        "  d = dict(Code=code, Lang=lang, Length_2020=round(rlen, 3))\n",
        "  if rest:\n",
        "    symbols, perp, pheb, sents = rest\n",
        "    d.update(dict(Symbols_2020=symbols, Perplexity_2020=round(perp, 1), Inefficiency_2020=round(perp / pheb * rlen, 3), Sentences_2020=sents))\n",
        "  if code in ted_para:\n",
        "    rlen, symbols, perp = ted_para[code][1:]\n",
        "    d.update(dict(Length_Parallel=round(rlen, 3), Symbols_Parallel=symbols, Perplexity_Parallel=round(perp, 1), Inefficiency_Parallel=round(perp / pheb_para * rlen, 3)))\n",
        "  output.append(d)\n",
        "for code, (lang, rlen, symbols, perp) in ted_para.items():\n",
        "  if code not in exclude and code not in ted_2020:\n",
        "    output.append(dict(Code=code, Lang=lang, Length_Parallel=round(rlen, 3), Symbols_Parallel=symbols, Perplexity_Parallel=round(perp, 1), Inefficiency_Parallel=round(perp / pheb_para * rlen, 3)))\n",
        "with open('compact.json', 'w') as f:\n",
        "  json.dump(output, f)"
      ],
      "metadata": {
        "id": "icHRv1sKEgyU"
      },
      "execution_count": 40,
      "outputs": []
    }
  ]
}